{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dasar Sistem Cerdas: Assignment 2:\n",
    "#### Name: Armand Faris A Surbakti\n",
    "#### NRP: 5023201051\n",
    "\n",
    "\n",
    "##### Design  McPit ANN Model for XOR function with 8 input variables. Realize computer program to simulate the model in realizing the logic function.\n",
    "##### Write your report of method of design to get your solution, realization of computer program to simulate the McPit ANN model of XOR 8 inputs.\n",
    "<img src=\"8 input model.png\" alt=\"8 input example\" width=500 height=250>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a program for 2nd DSC Assignment, McPit ANN Model for XOR Function\n",
    "\n",
    "#import  necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Next we are going to read the csv data for 8 inputs\n",
    "dataset = pd.read_csv('xor_8input.csv')\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is the csv data for the 8 input xor model. X here will be denoted as the input, and y will be the output layer. \n",
    "##### We use pandas library to split the data in x and y\n",
    "##### We can follow this notation as an example:\n",
    "<img src=\"x_y input model.png\" width=500 height=250>\n",
    "\n",
    "##### After this we encode the data here, as we see here, X is the input data and as a boolean data type (containing TRUE or FALSE)\n",
    "##### y as the output layer is also a boolean data type (containing TRUE or FALSE)\n",
    "##### the iloc function in pandas is used to retrieve data and split into columns and rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False  True]\n",
      " [False False False ... False  True False]\n",
      " ...\n",
      " [ True  True  True ...  True False  True]\n",
      " [ True  True  True ...  True  True False]\n",
      " [ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "#initiate the x input layer\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False, False,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True, False,  True,\n",
       "       False, False,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False,  True, False, False,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True,  True, False, False,  True,  True, False,  True, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False, False,  True,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False, False,  True, False,  True,  True, False, False,  True,\n",
       "        True, False,  True, False, False,  True,  True, False, False,\n",
       "        True, False,  True,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True, False,  True,\n",
       "       False, False,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False,  True, False, False,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False, False,  True, False,  True,  True, False, False,  True,\n",
       "        True, False,  True, False, False,  True, False,  True,  True,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inititate the y output layer\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To Simplify Visualization, we can convert the TRUE/FALSE data into just binary data (using 0s and 1s)\n",
    "##### This is also known as data encoding\n",
    "##### We can use the numpy multiply function here. numpy.multiply() function is used when we want to compute the multiplication of two arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_x = np.multiply(x,1)\n",
    "#convert encode_x into 0 and 1s arrays\n",
    "encode_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same process as y output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y = np.multiply(y,1)\n",
    "#convert encode_y into 0 and 1s arrays\n",
    "encoded_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After this encoding both x and y, we have to determine the total amount of inputs, rows, and TRUE outputs from the 8 inputs dataset\n",
    "##### We can use len to determine the total amount of input and sum of TRUE outputs in the y layer\n",
    "##### The purpose of this to find out about the Hidden layer. The Hidden layer is the layer that is inbetween the input and output of the algorithm\n",
    "##### the function applies weights to the inputs and directs the inputs through an activation function (in this case, y layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using len() to find out total amout of inputs\n",
    "n_input = len(x[0])\n",
    "#finding out the rows \n",
    "row = len(y)\n",
    "#sum of true in the output layer\n",
    "sum_true = y.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before we move forward, we need to determine TLU\n",
    "##### TLU is the threshold logic unit, it is a simple artificial neuron (also called the M-P Neuron) whose output it its thresholded total net input\n",
    "<img src=\"tlu_model.png\" alt=\"tlu model\" height = 200, width = 400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a tlu function for this input layer\n",
    "#convert it into an array using np.array()\n",
    "tlu = np.array([])\n",
    "for j in range(row):\n",
    "    if y[j] == 1:\n",
    "      #if output layer = TRUE, append exhibitory inputs\n",
    "      tlu = np.append(tlu, x[j].sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Weights\n",
    "##### Weight is the parameter within a neural network that transforms input data within the network's hidden layers. \n",
    "##### as an input enters the node, it gets multiplied by a weight value.\n",
    "<img src=\"weight_example.png\" alt=\"weight\">\n",
    "\n",
    "##### The weight of the first layer is done by converting the 0 inputs (false inputs) into -1\n",
    "##### We can follow this equation here, w=-c:\n",
    "<img src=\"weight_equation.png\"  alt=\"w\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., ..., -1., -1.,  1.],\n",
       "       [-1., -1., -1., ..., -1.,  1., -1.],\n",
       "       [-1., -1., -1., ...,  1., -1., -1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ..., -1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1., -1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1., -1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert weight layer into an array\n",
    "weight_layer1 = np.array([])\n",
    "for i in np.where(y == 1)[0]:\n",
    "        j = x[i]\n",
    "        cont = np.where(j == 0, -1, j)\n",
    "        #the numpy concatenate function is used to join 2 arrays into 1\n",
    "        weight_layer1 = np.concatenate((weight_layer1, cont))\n",
    "        #after computing the weights, we can use the reshape() to reshape the array\n",
    "weight_layer1 = weight_layer1.reshape((sum_true, n_input))\n",
    "\n",
    "weight_layer1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After computing the weights, we now move on to create and program the 1st layer\n",
    "##### We create variables specifically for our x input layer, and then move it to the threshold\n",
    "##### TLU will determine the output, which will move on to the 2nd layer\n",
    "##### if the inputs of layer 1 exceeds or level to threshold, then output 1\n",
    "##### if not, output will be 0 (in this case, an inhibitory neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set Variables\n",
    "#Remember that the input layers are the sum of all TRUE/0 variables\n",
    "in_layer1 = np.zeros(sum_true)\n",
    "#create an output layer for 1st layer\n",
    "out_layer1 = np.zeros(sum_true)\n",
    "for j in range(sum_true):\n",
    "    for k in range(n_input):\n",
    "        in_layer1[j] += weight_layer1[j,k] * x[1,k]\n",
    "    #if the inputs of layer 1 exceeds or level to threshold, then output 1\n",
    "    #if not, output 0 (in this case, an inhibitory neuron)\n",
    "    if in_layer1[j] >= tlu[j]:\n",
    "        out_layer1 [j] = 1\n",
    "    else:\n",
    "        out_layer1 [j] = 0\n",
    "out_layer1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the 2nd Layer:\n",
    "##### After creating and outputting the 1st layer, we move on the 2nd layer by doing the same process\n",
    "##### In this case the inputs here are the outputs of the 1st layer. Move it through threshold, and apply the same logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create second layer variables\n",
    "tlu_layer2 = 1\n",
    "weight_layer2 = np.ones(sum_true)\n",
    "in_layer2 = 0\n",
    "out_layer2 = 0\n",
    "\n",
    "#Initiate second layer\n",
    "for i in range(sum_true):\n",
    "   in_layer2 += weight_layer2[i] * out_layer1[i]\n",
    "#Apply TLU Logic\n",
    "if in_layer2 >= tlu_layer2:\n",
    "    out_layer2 = 1\n",
    "else:\n",
    "    out_layer2 = 0\n",
    "    \n",
    "out_layer2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output Layer = 1 means that the TLU and threshold worked.\n",
    "##### Next we will combine both layers (layer 1 and 2) into a single function\n",
    "##### The purpose of combining into 1 function is so that the model can be trained to output 1 set of a single truth_table\n",
    "##### Here, we use the same code from layers 1 and 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_layer_functon(input):\n",
    "    tlu = np.array([])\n",
    "    for j in range(row):\n",
    "       if y[j] == 1:\n",
    "          tlu = np.append(tlu, x[j].sum())\n",
    "    weight_layer1 = np.array([])\n",
    "    for i in np.where(y == 1)[0]:\n",
    "        j = x[i]\n",
    "        cont = np.where(j == 0, -1, j)\n",
    "        weight_layer1 = np.concatenate((weight_layer1, cont))\n",
    "    weight_layer1 = weight_layer1.reshape((sum_true, n_input))    \n",
    "    \n",
    "    #set variables for 1st layer  \n",
    "    in_layer1 = np.zeros(sum_true)\n",
    "    #create an output layer for 1st layer\n",
    "    out_layer1 = np.zeros(sum_true)\n",
    "    for j in range(sum_true):\n",
    "        for k in range(n_input):\n",
    "            in_layer1[j] += weight_layer1[j,k] * input[k]\n",
    "    #if the inputs of layer 1 exceeds or level to threshold, then output 1\n",
    "    #if not, output 0 (in this case, an inhibitory neuron)\n",
    "        if in_layer1[j] >= tlu[j]:\n",
    "           out_layer1 [j] = 1\n",
    "        else:\n",
    "           out_layer1 [j] = 0\n",
    "           \n",
    "    #Continute to the 2nd layer\n",
    "    tlu_layer2 = 1\n",
    "    weight_layer2 = np.ones(sum_true)\n",
    "    in_layer2 = 0\n",
    "    out_layer2 = 0\n",
    "    #Initiate second layer\n",
    "    for i in range(sum_true):\n",
    "        in_layer2 += weight_layer2[i] * out_layer1[i]\n",
    "    #Apply TLU Logic\n",
    "    if in_layer2 >= tlu_layer2:\n",
    "        out_layer2 = 1\n",
    "    else:\n",
    "        out_layer2 = 0\n",
    "    #return output of 2nd layer \n",
    "    return out_layer2\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculation for Input Set for Truth Table with for loop iteration to train the model\n",
    "##### This is the calculation process for every x input, which will be stored as \"y_function_output\" variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculation\n",
    "y_function_output = np.zeros(row)\n",
    "for i in range(row):\n",
    "    #apply the combined function into the x input\n",
    "    y_function_output[i] = combined_layer_functon(x[i])\n",
    "\n",
    "y_function_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Confusion Matrix to evaluate model calculation\n",
    "##### The Confusion Matrix is a specific table layout that allows visualization of the performance of an algorithm.\n",
    "##### In this case, it has 4 variable combination which is False Positive, False Negative, True Positive, True Negative\n",
    "##### False Neg and False Pos is an outcome where the model incorrectly predicts the negative class. While true positive is the outcome where the model correctly predicts the outcome.\n",
    "<img src=\"confusion matrix model.png\" alt=\"confused_matrix\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  128    0\n",
       "1    0  128"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create a 2x2 array since the confusion matrix is a 2x2 table.\n",
    "confusion_matrix = np.zeros((2,2))\n",
    "for i in range(row):\n",
    "    #False Positive\n",
    "    if (y_function_output[i] == y[i]) and (y_function_output[i] == 0): \n",
    "        confusion_matrix[0,0] += 1\n",
    "    #False Negative\n",
    "    elif (y_function_output[i] != y[i]) and (y_function_output[i] == 0): \n",
    "        confusion_matrix[0,1] += 1\n",
    "    #True Negative\n",
    "    elif (y_function_output[i] != y[i]) and (y_function_output[i] == 1):\n",
    "        confusion_matrix[1,0] += 1\n",
    "    #True Positive\n",
    "    elif (y_function_output[i] == y[i]) and (y_function_output[i] == 1):\n",
    "        confusion_matrix[1,1] += 1\n",
    "\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix, dtype=int)\n",
    "\n",
    "print('Confusion Matrix : ')\n",
    "confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After Creating the Confusion Matrix, we can now evaluate the accuracy \n",
    "##### We can use this formula to calculate our Model's Accuracy\n",
    "<img src =\"model_accuracy_equation.png\" alt=\"eq\">\n",
    "\n",
    "##### Based on the output of the confusion matrix, we can code it like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "#evaluation model accuracy\n",
    "false_negative = confusion_matrix.iloc[0,1]\n",
    "false_positive = confusion_matrix.iloc[0,0]\n",
    "true_negative =  confusion_matrix.iloc[1,0]\n",
    "true_positive = confusion_matrix.iloc[1,1]\n",
    "model_accuracy =  ((false_positive + true_positive) / (false_positive + true_positive + false_negative + true_negative))*100\n",
    "print(\"model_accuracy: {} %\".format(model_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c316c90eb089c847776c1b27e5e2aaf21e738d9fbbb5a1edbf7cd756aec46cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
